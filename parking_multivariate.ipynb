{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z87zg1ncLYJY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import  StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "G7bu2QZsMCj_",
        "outputId": "b57a431e-9067-405a-d968-b4e340ee10f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fd449ea4-e617-4f73-a129-391665449090\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fd449ea4-e617-4f73-a129-391665449090\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving newData.csv to newData.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('newData.csv')"
      ],
      "metadata": {
        "id": "LXbF9cLyM_AC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.size\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HVErhjf9NStc",
        "outputId": "ca060eb8-ca4d-47fd-824a-dd7f0c6f237d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Area name Departure time Arrive time  Duration time  Latitude   \\\n",
              "0      Dhanmondi        8:00 AM      5:30 PM       9:30:00  23.746053   \n",
              "1      Dhanmondi        9:00 AM      5:00 PM       8:00:00  23.746214   \n",
              "2        Gulshan        9:00 AM      7:30 PM      10:30:00  23.792964   \n",
              "3      Dhanmondi        9:00 AM      8:30 PM      11:30:00  23.749457   \n",
              "4        Gulshan       10:00 AM      6:00 PM       8:00:00  23.805708   \n",
              "..           ...            ...          ...           ...        ...   \n",
              "394  Mohammadpur        8:15 AM      8:00 PM           NaN  23.769499   \n",
              "395  Mohammadpur        9:00 AM      5:00 PM           NaN  23.769524   \n",
              "396  Mohammadpur       11:00 AM      2:00 PM           NaN  23.769343   \n",
              "397  Mohammadpur        6:00 PM      3:00 PM           NaN  23.769339   \n",
              "398  Mohammadpur        5:30 PM      4:00 PM           NaN  23.769312   \n",
              "\n",
              "     Longitude  \n",
              "0    90.376219  \n",
              "1    90.376522  \n",
              "2    90.404443  \n",
              "3    90.375497  \n",
              "4    90.418652  \n",
              "..         ...  \n",
              "394  90.354714  \n",
              "395  90.354853  \n",
              "396  90.354928  \n",
              "397  90.354783  \n",
              "398  90.354689  \n",
              "\n",
              "[399 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5162df87-9416-4f0a-b073-1a54a70e8a45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area name</th>\n",
              "      <th>Departure time</th>\n",
              "      <th>Arrive time</th>\n",
              "      <th>Duration time</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dhanmondi</td>\n",
              "      <td>8:00 AM</td>\n",
              "      <td>5:30 PM</td>\n",
              "      <td>9:30:00</td>\n",
              "      <td>23.746053</td>\n",
              "      <td>90.376219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dhanmondi</td>\n",
              "      <td>9:00 AM</td>\n",
              "      <td>5:00 PM</td>\n",
              "      <td>8:00:00</td>\n",
              "      <td>23.746214</td>\n",
              "      <td>90.376522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gulshan</td>\n",
              "      <td>9:00 AM</td>\n",
              "      <td>7:30 PM</td>\n",
              "      <td>10:30:00</td>\n",
              "      <td>23.792964</td>\n",
              "      <td>90.404443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dhanmondi</td>\n",
              "      <td>9:00 AM</td>\n",
              "      <td>8:30 PM</td>\n",
              "      <td>11:30:00</td>\n",
              "      <td>23.749457</td>\n",
              "      <td>90.375497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gulshan</td>\n",
              "      <td>10:00 AM</td>\n",
              "      <td>6:00 PM</td>\n",
              "      <td>8:00:00</td>\n",
              "      <td>23.805708</td>\n",
              "      <td>90.418652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>Mohammadpur</td>\n",
              "      <td>8:15 AM</td>\n",
              "      <td>8:00 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.769499</td>\n",
              "      <td>90.354714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Mohammadpur</td>\n",
              "      <td>9:00 AM</td>\n",
              "      <td>5:00 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.769524</td>\n",
              "      <td>90.354853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Mohammadpur</td>\n",
              "      <td>11:00 AM</td>\n",
              "      <td>2:00 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.769343</td>\n",
              "      <td>90.354928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Mohammadpur</td>\n",
              "      <td>6:00 PM</td>\n",
              "      <td>3:00 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.769339</td>\n",
              "      <td>90.354783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>Mohammadpur</td>\n",
              "      <td>5:30 PM</td>\n",
              "      <td>4:00 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.769312</td>\n",
              "      <td>90.354689</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>399 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5162df87-9416-4f0a-b073-1a54a70e8a45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5162df87-9416-4f0a-b073-1a54a70e8a45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5162df87-9416-4f0a-b073-1a54a70e8a45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Area name'] = df['Area name'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "oUZJJ1EGaosP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Arrive time '] = df['Arrive time '].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "XsyEN5i7Ws2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Departure time'] = df['Departure time'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "SFepaQHR5LQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['Duration time']"
      ],
      "metadata": {
        "id": "6qQ0urkrPAvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df)[0:5]\n",
        "#nparray = np.array(df)[:,1:3]\n",
        "\n"
      ],
      "metadata": {
        "id": "Ea4-6U31OfuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training = df[cols].astype(float)"
      ],
      "metadata": {
        "id": "BZoW4ZKnOvgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iHqZQ3RGTTXo",
        "outputId": "10e438db-3156-42b5-e390-8bce0015503a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Area name  Departure time  Arrive time   Latitude   Longitude\n",
              "0          0.0            22.0          16.0  23.746053  90.376219\n",
              "1          0.0            29.0          13.0  23.746214  90.376522\n",
              "2          1.0            29.0          20.0  23.792964  90.404443\n",
              "3          0.0            29.0          23.0  23.749457  90.375497\n",
              "4          1.0             0.0          17.0  23.805708  90.418652\n",
              "..         ...             ...           ...        ...        ...\n",
              "394        4.0            25.0          22.0  23.769499  90.354714\n",
              "395        4.0            29.0          13.0  23.769524  90.354853\n",
              "396        4.0             4.0           8.0  23.769343  90.354928\n",
              "397        4.0            13.0           9.0  23.769339  90.354783\n",
              "398        4.0            12.0          11.0  23.769312  90.354689\n",
              "\n",
              "[399 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-643522b7-3f4d-4a1f-b512-aee6393b2eb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area name</th>\n",
              "      <th>Departure time</th>\n",
              "      <th>Arrive time</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.746053</td>\n",
              "      <td>90.376219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.746214</td>\n",
              "      <td>90.376522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.792964</td>\n",
              "      <td>90.404443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.749457</td>\n",
              "      <td>90.375497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.805708</td>\n",
              "      <td>90.418652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>4.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>23.769499</td>\n",
              "      <td>90.354714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>4.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.769524</td>\n",
              "      <td>90.354853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>23.769343</td>\n",
              "      <td>90.354928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>23.769339</td>\n",
              "      <td>90.354783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.769312</td>\n",
              "      <td>90.354689</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>399 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-643522b7-3f4d-4a1f-b512-aee6393b2eb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-643522b7-3f4d-4a1f-b512-aee6393b2eb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-643522b7-3f4d-4a1f-b512-aee6393b2eb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=7)"
      ],
      "metadata": {
        "id": "zgi-uauua-JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#centers = kmeans.cluster_centers_\n",
        "y_pred = kmeans.fit_predict(df_for_training[['Latitude ','Longitude']])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLkNA4LebqKv",
        "outputId": "0970f1af-16b6-443d-d2f6-7b1e1def1710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 5, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4,\n",
              "       4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 1, 1, 5, 5, 5, 5, 5, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
              "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 5, 5, 5,\n",
              "       5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n",
              "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training['cluster'] = y_pred\n",
        "df_for_training.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZFl4jPL-b2fU",
        "outputId": "ee983400-17c4-4f60-cf54-1e00038544b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Area name  Departure time  Arrive time   Latitude   Longitude  cluster\n",
              "0        0.0            22.0          16.0  23.746053  90.376219        0\n",
              "1        0.0            29.0          13.0  23.746214  90.376522        0\n",
              "2        1.0            29.0          20.0  23.792964  90.404443        5\n",
              "3        0.0            29.0          23.0  23.749457  90.375497        0\n",
              "4        1.0             0.0          17.0  23.805708  90.418652        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c29c488-3489-434a-bd91-b1a1d2852334\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Area name</th>\n",
              "      <th>Departure time</th>\n",
              "      <th>Arrive time</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.746053</td>\n",
              "      <td>90.376219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>23.746214</td>\n",
              "      <td>90.376522</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>23.792964</td>\n",
              "      <td>90.404443</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>23.749457</td>\n",
              "      <td>90.375497</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>23.805708</td>\n",
              "      <td>90.418652</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c29c488-3489-434a-bd91-b1a1d2852334')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c29c488-3489-434a-bd91-b1a1d2852334 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c29c488-3489-434a-bd91-b1a1d2852334');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_for_training.plot.scatter(x= 'Latitude ', y= 'Longitude', c=y_pred, s=50, cmap='viridis' )\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "2gLCR5M5eSfU",
        "outputId": "c86af882-af94-4ea9-f527-538a76fca842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fa71016b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DATA = []\n",
        "errorRMSE = []\n",
        "errorMAE = []\n",
        "auc = []"
      ],
      "metadata": {
        "id": "OfwEm9WyZV7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(7):\n",
        "  train_DATA.insert(i, df_for_training[df_for_training.cluster==i])\n",
        "\n",
        "  cols = list(train_DATA[i])[1:3]\n",
        "  train_DATA[i] = train_DATA[i][cols]\n",
        "\n",
        "  scaler= MinMaxScaler(feature_range=(0,1))\n",
        "  train_DATA[i]= scaler.fit_transform(np.array(train_DATA[i]))\n",
        "\n",
        "  train_size = int(len(train_DATA[i])*0.65)\n",
        "  test_size = len(train_DATA[i])-train_size\n",
        "  traindata, testdata = train_DATA[i][0:train_size,:], train_DATA[i][0:test_size,:]\n",
        "\n",
        "  trainX = []\n",
        "  trainY = []\n",
        "  testX = []\n",
        "  testY = []\n",
        "\n",
        "  n_future = 1\n",
        "  n_past = 3\n",
        "\n",
        "  for j in range(3, len(traindata) - n_future + 1):\n",
        "    trainX.append(traindata[j - n_past:j, 0:traindata.shape[1]])\n",
        "    trainY.append(traindata[j + n_future - 1:j + n_future, 0:testdata.shape[1]])\n",
        "\n",
        "  for j in range(3, len(testdata) - n_future + 1):\n",
        "    testX.append(testdata[j - n_past:j, 0:testdata.shape[1]])\n",
        "    testY.append(testdata[j + n_future - 1:j + n_future, 0:testdata.shape[1]])\n",
        "\n",
        "  trainX, trainY = np.array(trainX), np.array(trainY)\n",
        "  testX, testY = np.array(testX), np.array(testY)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, activation='sigmoid', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences = True))\n",
        "  model.add(LSTM(64, activation= 'sigmoid', return_sequences= False))\n",
        "  model.add(Dropout(0.7))\n",
        "  model.add(Dense(trainY.shape[2]))\n",
        "\n",
        "\n",
        "\n",
        "  model.compile(optimizer= keras.optimizers.Adam(lr=0.01), loss='mse')\n",
        "  model.summary()\n",
        "\n",
        "  history = model.fit(trainX, trainY, epochs= 100, batch_size=16, validation_split = 0.1, verbose=1)\n",
        "\n",
        "  plt.plot(history.history['loss'], label = 'Training loss')\n",
        "  plt.plot(history.history['val_loss'], label = 'validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  train_predict = model.predict(trainX)\n",
        "  test_predict = model.predict(testX)\n",
        "\n",
        "  #train_predict =scaler.inverse_transform(train_predict)\n",
        "  #test_predict =scaler.inverse_transform(test_predict)\n",
        "\n",
        "  trainYreshape = np.reshape(trainY,(train_size-3,2))\n",
        "  testYreshape = np.reshape(testY,(test_size-3,2))\n",
        "\n",
        "  #testYreshape_inverse = scaler.inverse_transform(testYreshape)\n",
        "\n",
        "  #error = math.sqrt(mean_squared_error(testYreshape_inverse,test_predict))\n",
        "\n",
        "  errorRMSE.insert(i, math.sqrt(mean_squared_error(testYreshape,test_predict)))\n",
        "  errorMAE.insert(i,mae(testYreshape,test_predict))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X3KsUzTYaGa",
        "outputId": "0572e6dc-214f-4888-96d3-1e9275b182fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 6s 171ms/step - loss: 0.6006 - val_loss: 0.1307\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3307 - val_loss: 0.0648\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1708 - val_loss: 0.0438\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1501 - val_loss: 0.0332\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1003 - val_loss: 0.0436\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0978 - val_loss: 0.0560\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0797 - val_loss: 0.0475\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0738 - val_loss: 0.0373\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0743 - val_loss: 0.0349\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0653 - val_loss: 0.0361\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0630 - val_loss: 0.0376\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0632 - val_loss: 0.0361\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0624 - val_loss: 0.0353\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0575 - val_loss: 0.0352\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0654 - val_loss: 0.0363\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0663 - val_loss: 0.0405\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0616 - val_loss: 0.0386\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0597 - val_loss: 0.0361\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0560 - val_loss: 0.0367\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0570 - val_loss: 0.0405\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0554 - val_loss: 0.0419\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0555 - val_loss: 0.0368\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0613 - val_loss: 0.0349\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0515 - val_loss: 0.0358\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0570 - val_loss: 0.0375\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0534 - val_loss: 0.0371\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0478 - val_loss: 0.0357\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0518 - val_loss: 0.0351\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0483 - val_loss: 0.0352\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0503 - val_loss: 0.0352\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0511 - val_loss: 0.0361\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0481 - val_loss: 0.0380\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0500 - val_loss: 0.0391\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0515 - val_loss: 0.0366\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0502 - val_loss: 0.0350\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0463 - val_loss: 0.0350\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0449 - val_loss: 0.0354\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0444 - val_loss: 0.0361\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0461 - val_loss: 0.0367\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0464 - val_loss: 0.0371\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0465 - val_loss: 0.0365\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0470 - val_loss: 0.0361\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0450 - val_loss: 0.0359\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0477 - val_loss: 0.0364\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0436 - val_loss: 0.0365\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0431 - val_loss: 0.0354\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0452 - val_loss: 0.0351\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0430 - val_loss: 0.0352\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0421 - val_loss: 0.0354\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0446 - val_loss: 0.0359\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0439 - val_loss: 0.0361\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0435 - val_loss: 0.0359\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0422 - val_loss: 0.0358\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0444 - val_loss: 0.0356\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0421 - val_loss: 0.0362\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0431 - val_loss: 0.0364\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0430 - val_loss: 0.0355\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0439 - val_loss: 0.0348\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0446 - val_loss: 0.0349\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0428 - val_loss: 0.0352\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0413 - val_loss: 0.0356\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0419 - val_loss: 0.0358\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0426 - val_loss: 0.0358\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0414 - val_loss: 0.0358\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0433 - val_loss: 0.0359\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0418 - val_loss: 0.0358\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0416 - val_loss: 0.0360\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0414 - val_loss: 0.0358\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0411 - val_loss: 0.0355\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0414 - val_loss: 0.0353\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0414 - val_loss: 0.0352\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0396 - val_loss: 0.0352\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0409 - val_loss: 0.0352\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0415 - val_loss: 0.0353\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0402 - val_loss: 0.0355\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0354\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0411 - val_loss: 0.0353\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0406 - val_loss: 0.0352\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0407 - val_loss: 0.0354\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0400 - val_loss: 0.0355\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0408 - val_loss: 0.0354\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0399 - val_loss: 0.0354\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0394 - val_loss: 0.0355\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0398 - val_loss: 0.0355\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0402 - val_loss: 0.0355\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0401 - val_loss: 0.0355\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0396 - val_loss: 0.0354\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0396 - val_loss: 0.0354\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0396 - val_loss: 0.0354\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0394 - val_loss: 0.0354\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0395 - val_loss: 0.0352\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0351\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0399 - val_loss: 0.0352\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0394 - val_loss: 0.0354\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - val_loss: 0.0354\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0397 - val_loss: 0.0355\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0397 - val_loss: 0.0355\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0397 - val_loss: 0.0354\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0395 - val_loss: 0.0352\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0394 - val_loss: 0.0352\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 160ms/step - loss: 0.8716 - val_loss: 0.1374\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.2947 - val_loss: 0.1296\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.2840 - val_loss: 0.0994\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2215 - val_loss: 0.0806\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1725 - val_loss: 0.0867\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1490 - val_loss: 0.1034\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1506 - val_loss: 0.1126\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1366 - val_loss: 0.1129\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1239 - val_loss: 0.1123\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1179 - val_loss: 0.1101\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1245 - val_loss: 0.1073\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1177 - val_loss: 0.1068\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1211 - val_loss: 0.1049\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1191 - val_loss: 0.1041\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1186 - val_loss: 0.1011\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1157 - val_loss: 0.0977\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1095 - val_loss: 0.0953\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1106 - val_loss: 0.0933\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1106 - val_loss: 0.0912\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1147 - val_loss: 0.0887\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1158 - val_loss: 0.0908\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1112 - val_loss: 0.0974\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1106 - val_loss: 0.1029\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1100 - val_loss: 0.1050\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1078 - val_loss: 0.1042\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1117 - val_loss: 0.1029\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1037 - val_loss: 0.1038\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1065 - val_loss: 0.1064\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.1133 - val_loss: 0.1046\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1081 - val_loss: 0.1004\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1013 - val_loss: 0.1001\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1046 - val_loss: 0.1025\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1025 - val_loss: 0.1062\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1019 - val_loss: 0.1076\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1019 - val_loss: 0.1080\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1085 - val_loss: 0.1054\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1039 - val_loss: 0.1022\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1039 - val_loss: 0.1000\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1010 - val_loss: 0.0975\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1022 - val_loss: 0.0958\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1010 - val_loss: 0.0964\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0989 - val_loss: 0.0962\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1013 - val_loss: 0.0957\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1012 - val_loss: 0.0950\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1002 - val_loss: 0.0965\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1001 - val_loss: 0.0964\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1006 - val_loss: 0.0966\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0978 - val_loss: 0.0989\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0976 - val_loss: 0.1001\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0990 - val_loss: 0.1012\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0982 - val_loss: 0.1038\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0959 - val_loss: 0.1056\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0981 - val_loss: 0.1069\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0991 - val_loss: 0.1069\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0985 - val_loss: 0.1070\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0999 - val_loss: 0.1064\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0958 - val_loss: 0.1062\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0971 - val_loss: 0.1043\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0987 - val_loss: 0.1021\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0981 - val_loss: 0.1007\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0971 - val_loss: 0.0977\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0967 - val_loss: 0.0963\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0974 - val_loss: 0.0953\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0975 - val_loss: 0.0953\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0965 - val_loss: 0.0963\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0964 - val_loss: 0.0976\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0970 - val_loss: 0.0985\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0950 - val_loss: 0.0991\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0953 - val_loss: 0.0999\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0954 - val_loss: 0.0995\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0956 - val_loss: 0.0999\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0953 - val_loss: 0.1019\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0948 - val_loss: 0.1039\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0958 - val_loss: 0.1051\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0955 - val_loss: 0.1057\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0960 - val_loss: 0.1053\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0975 - val_loss: 0.1048\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0949 - val_loss: 0.1050\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0952 - val_loss: 0.1040\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0946 - val_loss: 0.1029\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0948 - val_loss: 0.1023\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0945 - val_loss: 0.1007\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0950 - val_loss: 0.0993\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0939 - val_loss: 0.0981\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0958 - val_loss: 0.0971\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0956 - val_loss: 0.0975\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0953 - val_loss: 0.0972\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0946 - val_loss: 0.0977\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0939 - val_loss: 0.0996\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0947 - val_loss: 0.1016\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0941 - val_loss: 0.1009\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0953 - val_loss: 0.1000\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0938 - val_loss: 0.0995\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0950 - val_loss: 0.0989\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0941 - val_loss: 0.0998\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0943 - val_loss: 0.1002\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0945 - val_loss: 0.1017\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0944 - val_loss: 0.1024\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0950 - val_loss: 0.1022\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0933 - val_loss: 0.1012\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 2s 318ms/step - loss: 0.8500 - val_loss: 0.2466\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3332 - val_loss: 0.0453\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3896 - val_loss: 0.0298\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2688 - val_loss: 0.0429\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2129 - val_loss: 0.0693\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1696 - val_loss: 0.1057\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1371 - val_loss: 0.1245\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1173 - val_loss: 0.1210\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1185 - val_loss: 0.1073\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1272 - val_loss: 0.0942\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1006 - val_loss: 0.0820\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1180 - val_loss: 0.0735\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1218 - val_loss: 0.0708\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1066 - val_loss: 0.0747\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0974 - val_loss: 0.0820\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1003 - val_loss: 0.0854\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0963 - val_loss: 0.0876\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0946 - val_loss: 0.0932\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1081 - val_loss: 0.0967\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0851 - val_loss: 0.1010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0832 - val_loss: 0.1038\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0969 - val_loss: 0.1054\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0854 - val_loss: 0.1031\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0939 - val_loss: 0.0989\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0906 - val_loss: 0.0954\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0857 - val_loss: 0.0897\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0925 - val_loss: 0.0869\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0967 - val_loss: 0.0842\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0836 - val_loss: 0.0837\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0924 - val_loss: 0.0795\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0821 - val_loss: 0.0798\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0827 - val_loss: 0.0844\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0850 - val_loss: 0.0909\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0836 - val_loss: 0.0987\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0811 - val_loss: 0.1038\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0811 - val_loss: 0.1050\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0807 - val_loss: 0.1026\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0874 - val_loss: 0.0987\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0841 - val_loss: 0.0959\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0841 - val_loss: 0.0931\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0796 - val_loss: 0.0909\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0815 - val_loss: 0.0895\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0817 - val_loss: 0.0887\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0824 - val_loss: 0.0891\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0785 - val_loss: 0.0915\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0799 - val_loss: 0.0921\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0771 - val_loss: 0.0937\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0757 - val_loss: 0.0930\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0782 - val_loss: 0.0944\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0775 - val_loss: 0.0985\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0799 - val_loss: 0.1029\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0815 - val_loss: 0.1053\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0780 - val_loss: 0.1052\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0768 - val_loss: 0.1054\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0745 - val_loss: 0.1057\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0812 - val_loss: 0.1024\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0781 - val_loss: 0.0945\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0808 - val_loss: 0.0921\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0787 - val_loss: 0.0903\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0788 - val_loss: 0.0931\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0798 - val_loss: 0.0960\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0769 - val_loss: 0.1030\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0755 - val_loss: 0.1091\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0784 - val_loss: 0.1117\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0757 - val_loss: 0.1144\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0769 - val_loss: 0.1137\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0769 - val_loss: 0.1068\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0772 - val_loss: 0.1014\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0764 - val_loss: 0.0975\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0766 - val_loss: 0.0967\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0753 - val_loss: 0.0974\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0736 - val_loss: 0.0978\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0739 - val_loss: 0.0983\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0750 - val_loss: 0.1003\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0745 - val_loss: 0.1012\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0745 - val_loss: 0.1005\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0733 - val_loss: 0.0984\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0752 - val_loss: 0.0959\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0744 - val_loss: 0.0953\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0757 - val_loss: 0.0956\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0762 - val_loss: 0.0970\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0748 - val_loss: 0.0994\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0733 - val_loss: 0.1008\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0743 - val_loss: 0.1007\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0724 - val_loss: 0.1007\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0749 - val_loss: 0.0997\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0724 - val_loss: 0.0969\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0728 - val_loss: 0.0954\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.0723 - val_loss: 0.0963\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0748 - val_loss: 0.0972\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.0729 - val_loss: 0.0997\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0714 - val_loss: 0.1045\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0724 - val_loss: 0.1105\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0725 - val_loss: 0.1136\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0717 - val_loss: 0.1184\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.0726 - val_loss: 0.1206\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0738 - val_loss: 0.1164\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0715 - val_loss: 0.1124\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0715 - val_loss: 0.1083\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0713 - val_loss: 0.1046\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 1.1502 - val_loss: 0.0457\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7212 - val_loss: 0.0979\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6928 - val_loss: 0.0142\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1840 - val_loss: 0.0035\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2849 - val_loss: 0.0273\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3061 - val_loss: 0.0422\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.2414 - val_loss: 0.0560\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2630 - val_loss: 0.0605\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1990 - val_loss: 0.0551\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2318 - val_loss: 0.0480\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1201 - val_loss: 0.0455\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1888 - val_loss: 0.0431\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1533 - val_loss: 0.0370\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1050 - val_loss: 0.0296\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1071 - val_loss: 0.0234\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1077 - val_loss: 0.0206\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1484 - val_loss: 0.0181\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1383 - val_loss: 0.0161\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1100 - val_loss: 0.0147\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0705 - val_loss: 0.0136\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1402 - val_loss: 0.0132\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1037 - val_loss: 0.0134\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1347 - val_loss: 0.0154\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0698 - val_loss: 0.0194\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0916 - val_loss: 0.0252\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0901 - val_loss: 0.0327\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1002 - val_loss: 0.0393\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0735 - val_loss: 0.0454\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1230 - val_loss: 0.0486\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0917 - val_loss: 0.0487\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0886 - val_loss: 0.0458\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0728 - val_loss: 0.0412\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0921 - val_loss: 0.0363\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0753 - val_loss: 0.0313\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0743 - val_loss: 0.0271\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0633 - val_loss: 0.0238\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0772 - val_loss: 0.0214\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0771 - val_loss: 0.0197\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0707 - val_loss: 0.0191\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0941 - val_loss: 0.0187\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1088 - val_loss: 0.0179\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0783 - val_loss: 0.0168\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0657 - val_loss: 0.0158\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0648 - val_loss: 0.0152\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0590 - val_loss: 0.0147\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0708 - val_loss: 0.0146\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0778 - val_loss: 0.0144\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0645 - val_loss: 0.0144\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0656 - val_loss: 0.0148\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0714 - val_loss: 0.0158\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0795 - val_loss: 0.0174\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0543 - val_loss: 0.0191\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0580 - val_loss: 0.0204\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0701 - val_loss: 0.0211\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0782 - val_loss: 0.0222\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0680 - val_loss: 0.0227\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0674 - val_loss: 0.0225\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0594 - val_loss: 0.0222\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0658 - val_loss: 0.0220\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0643 - val_loss: 0.0217\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0584 - val_loss: 0.0213\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0637 - val_loss: 0.0209\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0660 - val_loss: 0.0204\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0639 - val_loss: 0.0199\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0661 - val_loss: 0.0195\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0717 - val_loss: 0.0194\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0613 - val_loss: 0.0198\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0635 - val_loss: 0.0201\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0606 - val_loss: 0.0203\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0621 - val_loss: 0.0205\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0626 - val_loss: 0.0202\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0619 - val_loss: 0.0193\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0630 - val_loss: 0.0183\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0594 - val_loss: 0.0175\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0580 - val_loss: 0.0170\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0610 - val_loss: 0.0167\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0546 - val_loss: 0.0166\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0630 - val_loss: 0.0167\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0602 - val_loss: 0.0169\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0647 - val_loss: 0.0171\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0673 - val_loss: 0.0175\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0652 - val_loss: 0.0179\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0615 - val_loss: 0.0184\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0537 - val_loss: 0.0186\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0577 - val_loss: 0.0188\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0546 - val_loss: 0.0190\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0559 - val_loss: 0.0190\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0545 - val_loss: 0.0190\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0550 - val_loss: 0.0191\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0600 - val_loss: 0.0190\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0565 - val_loss: 0.0188\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0584 - val_loss: 0.0189\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0580 - val_loss: 0.0192\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0568 - val_loss: 0.0196\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0611 - val_loss: 0.0199\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0567 - val_loss: 0.0201\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0614 - val_loss: 0.0198\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0562 - val_loss: 0.0194\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0624 - val_loss: 0.0189\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0544 - val_loss: 0.0182\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.8686 - val_loss: 0.2302\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.7904 - val_loss: 0.8862\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6408 - val_loss: 0.3649\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8788 - val_loss: 0.1460\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5748 - val_loss: 0.2619\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4481 - val_loss: 0.4295\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5491 - val_loss: 0.5423\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3786 - val_loss: 0.5971\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5505 - val_loss: 0.6054\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3628 - val_loss: 0.5873\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4975 - val_loss: 0.5519\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5155 - val_loss: 0.5084\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3507 - val_loss: 0.4637\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4867 - val_loss: 0.4155\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3451 - val_loss: 0.3734\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3471 - val_loss: 0.3334\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2899 - val_loss: 0.2984\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.3073 - val_loss: 0.2691\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2338 - val_loss: 0.2458\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2346 - val_loss: 0.2261\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2253 - val_loss: 0.2093\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1854 - val_loss: 0.1966\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1809 - val_loss: 0.1870\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1964 - val_loss: 0.1782\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2093 - val_loss: 0.1727\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1782 - val_loss: 0.1681\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1961 - val_loss: 0.1657\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2058 - val_loss: 0.1655\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1833 - val_loss: 0.1657\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2041 - val_loss: 0.1670\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1771 - val_loss: 0.1691\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1580 - val_loss: 0.1703\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1829 - val_loss: 0.1720\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2538 - val_loss: 0.1748\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2120 - val_loss: 0.1780\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1675 - val_loss: 0.1813\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1818 - val_loss: 0.1843\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1644 - val_loss: 0.1870\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1680 - val_loss: 0.1903\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1602 - val_loss: 0.1934\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1799 - val_loss: 0.1973\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1720 - val_loss: 0.2008\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1860 - val_loss: 0.2039\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1693 - val_loss: 0.2068\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.1643 - val_loss: 0.2094\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1716 - val_loss: 0.2109\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1681 - val_loss: 0.2119\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1644 - val_loss: 0.2122\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1688 - val_loss: 0.2125\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.1778 - val_loss: 0.2117\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1692 - val_loss: 0.2101\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1665 - val_loss: 0.2079\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1607 - val_loss: 0.2054\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1548 - val_loss: 0.2036\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1656 - val_loss: 0.2013\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1732 - val_loss: 0.1988\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1726 - val_loss: 0.1959\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1600 - val_loss: 0.1934\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1562 - val_loss: 0.1908\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1488 - val_loss: 0.1889\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1711 - val_loss: 0.1874\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1766 - val_loss: 0.1861\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1621 - val_loss: 0.1845\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1577 - val_loss: 0.1827\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1584 - val_loss: 0.1806\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1572 - val_loss: 0.1785\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1566 - val_loss: 0.1768\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1560 - val_loss: 0.1775\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1663 - val_loss: 0.1791\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1700 - val_loss: 0.1817\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1552 - val_loss: 0.1851\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1522 - val_loss: 0.1885\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1561 - val_loss: 0.1920\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1584 - val_loss: 0.1953\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1600 - val_loss: 0.1986\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1774 - val_loss: 0.2034\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1554 - val_loss: 0.2075\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1522 - val_loss: 0.2105\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1673 - val_loss: 0.2121\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1607 - val_loss: 0.2128\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1531 - val_loss: 0.2123\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1549 - val_loss: 0.2117\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1492 - val_loss: 0.2108\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1676 - val_loss: 0.2104\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1579 - val_loss: 0.2106\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1675 - val_loss: 0.2113\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1613 - val_loss: 0.2105\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1528 - val_loss: 0.2095\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1502 - val_loss: 0.2074\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1534 - val_loss: 0.2045\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1668 - val_loss: 0.2009\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1562 - val_loss: 0.1982\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1549 - val_loss: 0.1947\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1602 - val_loss: 0.1907\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.1493 - val_loss: 0.1883\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.1559 - val_loss: 0.1854\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.1653 - val_loss: 0.1826\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.1528 - val_loss: 0.1799\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.1628 - val_loss: 0.1770\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1595 - val_loss: 0.1740\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1bae34bb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_10 (LSTM)              (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 169ms/step - loss: 0.8721 - val_loss: 0.2743\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.3391 - val_loss: 0.1613\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3104 - val_loss: 0.1331\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1978 - val_loss: 0.1379\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1561 - val_loss: 0.1470\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1321 - val_loss: 0.1547\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.1253 - val_loss: 0.1616\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1196 - val_loss: 0.1591\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1166 - val_loss: 0.1550\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.1145 - val_loss: 0.1483\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1116 - val_loss: 0.1458\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1078 - val_loss: 0.1479\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1115 - val_loss: 0.1483\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1071 - val_loss: 0.1484\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1062 - val_loss: 0.1474\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1073 - val_loss: 0.1475\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1062 - val_loss: 0.1465\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1078 - val_loss: 0.1497\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1064 - val_loss: 0.1522\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1073 - val_loss: 0.1523\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1082 - val_loss: 0.1515\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1019 - val_loss: 0.1489\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1032 - val_loss: 0.1497\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1036 - val_loss: 0.1480\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1015 - val_loss: 0.1478\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0982 - val_loss: 0.1501\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1006 - val_loss: 0.1475\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0986 - val_loss: 0.1448\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1000 - val_loss: 0.1465\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0969 - val_loss: 0.1473\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.1020 - val_loss: 0.1490\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1026 - val_loss: 0.1512\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.1022 - val_loss: 0.1527\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0999 - val_loss: 0.1525\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0971 - val_loss: 0.1529\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0998 - val_loss: 0.1520\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0994 - val_loss: 0.1489\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0976 - val_loss: 0.1457\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0993 - val_loss: 0.1447\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0980 - val_loss: 0.1470\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0980 - val_loss: 0.1487\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0970 - val_loss: 0.1507\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0970 - val_loss: 0.1510\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0955 - val_loss: 0.1511\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0967 - val_loss: 0.1524\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0962 - val_loss: 0.1524\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0965 - val_loss: 0.1508\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0962 - val_loss: 0.1485\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0980 - val_loss: 0.1483\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0945 - val_loss: 0.1479\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0954 - val_loss: 0.1485\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0942 - val_loss: 0.1490\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0960 - val_loss: 0.1499\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0950 - val_loss: 0.1517\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0961 - val_loss: 0.1521\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0946 - val_loss: 0.1519\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0964 - val_loss: 0.1485\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0951 - val_loss: 0.1476\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0946 - val_loss: 0.1490\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0941 - val_loss: 0.1511\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0938 - val_loss: 0.1512\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0938 - val_loss: 0.1513\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0935 - val_loss: 0.1529\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0945 - val_loss: 0.1532\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0948 - val_loss: 0.1526\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0945 - val_loss: 0.1509\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0936 - val_loss: 0.1510\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0951 - val_loss: 0.1527\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0939 - val_loss: 0.1535\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0939 - val_loss: 0.1542\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0949 - val_loss: 0.1543\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0937 - val_loss: 0.1537\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0939 - val_loss: 0.1525\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0937 - val_loss: 0.1523\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0930 - val_loss: 0.1524\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0930 - val_loss: 0.1521\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0935 - val_loss: 0.1516\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0928 - val_loss: 0.1505\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0933 - val_loss: 0.1499\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0931 - val_loss: 0.1511\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0930 - val_loss: 0.1522\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0927 - val_loss: 0.1524\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0932 - val_loss: 0.1527\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0933 - val_loss: 0.1529\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0929 - val_loss: 0.1540\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0926 - val_loss: 0.1547\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0916 - val_loss: 0.1546\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0927 - val_loss: 0.1551\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0926 - val_loss: 0.1545\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0925 - val_loss: 0.1533\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0924 - val_loss: 0.1520\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0925 - val_loss: 0.1522\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0928 - val_loss: 0.1523\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0935 - val_loss: 0.1520\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0930 - val_loss: 0.1534\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0928 - val_loss: 0.1527\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0924 - val_loss: 0.1528\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0919 - val_loss: 0.1520\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0928 - val_loss: 0.1523\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0930 - val_loss: 0.1524\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1b96382e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_12 (LSTM)              (None, 3, 128)            67072     \n",
            "                                                                 \n",
            " lstm_13 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,610\n",
            "Trainable params: 116,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 167ms/step - loss: 0.6590 - val_loss: 0.0626\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3054 - val_loss: 0.3538\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2855 - val_loss: 0.3369\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2369 - val_loss: 0.1547\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1473 - val_loss: 0.0816\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1634 - val_loss: 0.0658\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1166 - val_loss: 0.0717\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1104 - val_loss: 0.0810\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.1084 - val_loss: 0.0923\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1152 - val_loss: 0.1088\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.1060 - val_loss: 0.1237\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1034 - val_loss: 0.1233\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.1006 - val_loss: 0.1156\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0973 - val_loss: 0.1113\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0984 - val_loss: 0.1045\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0945 - val_loss: 0.1042\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0978 - val_loss: 0.1014\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0934 - val_loss: 0.1061\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.1006 - val_loss: 0.1149\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.1014 - val_loss: 0.1114\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0936 - val_loss: 0.1021\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0921 - val_loss: 0.0934\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0928 - val_loss: 0.0936\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0907 - val_loss: 0.0924\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0942 - val_loss: 0.0962\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0934 - val_loss: 0.1046\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0870 - val_loss: 0.1109\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0921 - val_loss: 0.1147\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.0911 - val_loss: 0.1153\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 0.0856 - val_loss: 0.1161\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0853 - val_loss: 0.1117\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0897 - val_loss: 0.1079\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0891 - val_loss: 0.1040\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0900 - val_loss: 0.1048\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0877 - val_loss: 0.1078\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0865 - val_loss: 0.1101\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0907 - val_loss: 0.1166\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0869 - val_loss: 0.1187\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0877 - val_loss: 0.1128\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0873 - val_loss: 0.1101\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0855 - val_loss: 0.1088\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0844 - val_loss: 0.1085\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0883 - val_loss: 0.1077\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0843 - val_loss: 0.1063\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0834 - val_loss: 0.1076\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0871 - val_loss: 0.1070\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0856 - val_loss: 0.1054\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0844 - val_loss: 0.1023\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0866 - val_loss: 0.0999\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0837 - val_loss: 0.1052\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0815 - val_loss: 0.1082\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0855 - val_loss: 0.1095\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0836 - val_loss: 0.1098\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0831 - val_loss: 0.1128\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0849 - val_loss: 0.1149\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0856 - val_loss: 0.1156\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0849 - val_loss: 0.1099\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0848 - val_loss: 0.1039\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0817 - val_loss: 0.1011\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0830 - val_loss: 0.0995\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0821 - val_loss: 0.0981\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0834 - val_loss: 0.0952\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0821 - val_loss: 0.0940\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0820 - val_loss: 0.0912\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0833 - val_loss: 0.0905\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0807 - val_loss: 0.0921\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0804 - val_loss: 0.0966\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0811 - val_loss: 0.0999\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0827 - val_loss: 0.1000\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0833 - val_loss: 0.1015\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0808 - val_loss: 0.1017\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0810 - val_loss: 0.1003\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0821 - val_loss: 0.1023\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0830 - val_loss: 0.1026\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0824 - val_loss: 0.1020\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0803 - val_loss: 0.1005\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0804 - val_loss: 0.0988\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0811 - val_loss: 0.0974\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0824 - val_loss: 0.1009\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0817 - val_loss: 0.1069\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0806 - val_loss: 0.1097\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0811 - val_loss: 0.1107\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0813 - val_loss: 0.1080\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0812 - val_loss: 0.1054\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0798 - val_loss: 0.1044\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0811 - val_loss: 0.1041\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0815 - val_loss: 0.1050\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0806 - val_loss: 0.1050\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0803 - val_loss: 0.1055\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0795 - val_loss: 0.1081\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0807 - val_loss: 0.1138\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0810 - val_loss: 0.1159\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0815 - val_loss: 0.1155\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0802 - val_loss: 0.1127\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0804 - val_loss: 0.1110\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0803 - val_loss: 0.1080\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0799 - val_loss: 0.1067\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0793 - val_loss: 0.1036\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0800 - val_loss: 0.1029\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0794 - val_loss: 0.1042\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errorRMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10c7oWWr49J",
        "outputId": "c4642449-a0a7-46e1-933a-653f1fe23a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29700362449084355,\n",
              " 0.31350545793983664,\n",
              " 0.19560652720747485,\n",
              " 0.4434208229281751,\n",
              " 0.2850126676561669,\n",
              " 0.22490179621634931,\n",
              " 0.30874923486792716]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errorMAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erv8lIlVKLV5",
        "outputId": "a39c287a-ddac-46f7-fc35-bd51c7177155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25027966016990755,\n",
              " 0.24664945446926614,\n",
              " 0.15246314372939448,\n",
              " 0.4042654623587926,\n",
              " 0.2305248933997783,\n",
              " 0.18668642226192686,\n",
              " 0.26571733506038936]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_avgRMSE = sum(errorRMSE)/len(errorRMSE)\n",
        "error_avgRMSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N5fmB3FVuZI",
        "outputId": "233263de-ade1-4439-8fff-bf42970a053b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29545716161525337"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_avgMAE = sum(errorMAE)/len(errorMAE)\n",
        "error_avgMAE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnXsPb0wKolW",
        "outputId": "675cdcd8-45b0-43b8-992c-873a1c164dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24808376734992219"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNp2iP-OPNgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_for_training1= df_for_training[df_for_training.cluster==0]\n",
        "#df_for_training2= df_for_training[df_for_training.cluster==1]\n",
        "#df_for_training3= df_for_training[df_for_training.cluster==2]\n",
        "#df_for_training4= df_for_training[df_for_training.cluster==3]\n",
        "#df_for_training5= df_for_training[df_for_training.cluster==4]\n",
        "#df_for_training6= df_for_training[df_for_training.cluster==5]\n",
        "#df_for_training7= df_for_training[df_for_training.cluster==6]"
      ],
      "metadata": {
        "id": "kKO2cNxxcTRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cols = list(df_for_training4)[1:3]\n",
        "#df_for_training4 = df_for_training4[cols]"
      ],
      "metadata": {
        "id": "bDMrzaW9eOKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaler = StandardScaler()\n",
        "#scaler = scaler.fit(df_for_training4)\n",
        "#df_for_training_scaled4 = scaler.transform(df_for_training4)\n",
        "\n",
        "#from sklearn.preprocessing import MinMaxScaler\n",
        "#scaler= MinMaxScaler(feature_range=(0,1))\n",
        "#df_for_training_scaled4= scaler.fit_transform(np.array(df_for_training_scaled4))\n",
        "\n"
      ],
      "metadata": {
        "id": "OEVlAybz8DyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_size = int(len(df_for_training_scaled4)*0.65)\n",
        "#test_size = len(df_for_training_scaled4)-train_size\n",
        "#traindata, testdata = df_for_training_scaled4[0:train_size,:], df_for_training_scaled4[0:test_size,:]\n",
        "#train_size, test_size"
      ],
      "metadata": {
        "id": "rcQtt6oegbuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c96c53c-70e8-46b1-b297-082911b73914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1109, 598)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainX = []\n",
        "#trainY = []\n",
        "#testX = []\n",
        "#testY = []"
      ],
      "metadata": {
        "id": "PiASqtEnBsSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#n_future = 1\n",
        "#n_past = 3"
      ],
      "metadata": {
        "id": "d9PcMR_8B-My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(n_past, len(traindata) - n_future + 1):\n",
        "#  trainX.append(traindata[i - n_past:i, 0:traindata.shape[1]])\n",
        "#  trainY.append(traindata[i + n_future - 1:i + n_future, 0:testdata.shape[1]])"
      ],
      "metadata": {
        "id": "90fDB45nCfuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(n_past, len(testdata) - n_future + 1):\n",
        "#  testX.append(testdata[i - n_past:i, 0:testdata.shape[1]])\n",
        "#  testY.append(testdata[i + n_future - 1:i + n_future, 0:testdata.shape[1]])"
      ],
      "metadata": {
        "id": "KaBqrVv7iMle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainX, trainY = np.array(trainX), np.array(trainY)"
      ],
      "metadata": {
        "id": "aOr57SIgD_Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testX, testY = np.array(testX), np.array(testY)"
      ],
      "metadata": {
        "id": "EqCYixdDiudP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainX, trainY\n"
      ],
      "metadata": {
        "id": "9U5cKMh1ELyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainY[:10]"
      ],
      "metadata": {
        "id": "zQmn6-r2EWCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testX[:10]"
      ],
      "metadata": {
        "id": "fMvwQznnFpwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testY[:10]"
      ],
      "metadata": {
        "id": "JOBE6dEYi95r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('trainX shape == {}.'.format(trainX.shape))\n",
        "#print('trainY shape == {}.'.format(trainY.shape))\n",
        "#trainX.shape[1], trainX.shape[2]"
      ],
      "metadata": {
        "id": "f6jjYGhFFuwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Sequential()\n",
        "#model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences = True))\n",
        "#model.add(LSTM(32, activation= 'relu', return_sequences= False))\n",
        "#model.add(Dropout(0.7))\n",
        "#model.add(Dense(trainY.shape[2]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cGAUuu_DG45_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer= 'adam', loss= 'mse')\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "A3Og66leIH-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#history = model.fit(trainX, trainY, epochs= 100, batch_size=64, validation_split = 0.1, verbose=1)"
      ],
      "metadata": {
        "id": "uRWMQA2WJPLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(history.history['loss'], label = 'Training loss')\n",
        "#plt.plot(history.history['val_loss'], label = 'validation loss')\n",
        "#plt.legend()"
      ],
      "metadata": {
        "id": "asFAO_uxKAZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_predict = model.predict(trainX)\n",
        "#test_predict = model.predict(testX)\n",
        "\n",
        "#trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "metadata": {
        "id": "8ydtiIIOLWvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_predict"
      ],
      "metadata": {
        "id": "KlKWZQ0lTBpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainX"
      ],
      "metadata": {
        "id": "pQBYBbfVTMSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_predict =scaler.inverse_transform(train_predict)\n",
        "#test_predict =scaler.inverse_transform(test_predict)"
      ],
      "metadata": {
        "id": "usElPgusVRya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_predict.shape, trainY.shape"
      ],
      "metadata": {
        "id": "ckYbp5-n7anM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainYreshape = np.reshape(trainY,(1106,2))\n",
        "#testYreshape = np.reshape(testY,(595,2))\n"
      ],
      "metadata": {
        "id": "eEL13W2J810Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import math\n",
        "#from sklearn.metrics import mean_squared_error\n",
        "#math.sqrt(mean_squared_error(trainYreshape,train_predict))\n",
        "#mean_squared_error(trainYreshape,train_predict)"
      ],
      "metadata": {
        "id": "ytW4fAsT7GfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#math.sqrt(mean_squared_error(testYreshape,test_predict))"
      ],
      "metadata": {
        "id": "6Kyc7eM09RUN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}